---
title: "Checkpoint3"
author: "Rodolfo Viana"
date: "04-06-2015"
output: html_document
---

Utilizando os dados disponíveis no [RecySys challenge 2015](http://2015.recsyschallenge.com/challenge.html) tentamos classificar uma sessão como compradora ou não. 

Os dados disponíveis podem ser encontrados [aqui](http://2015.recsyschallenge.com/). No dataset inicial temos os seguintes atributos:

1. Session ID – o ID de uma sessão. Uma sessão possui um ou mais clicks
2. Timestamp – o tempo em que o click aconteceu
3. Item ID – o ID de um item
4. Category – a categoria do item
6. Buy – informação se o item foi comprado ou não

Como esses atributos eram atributos básicos começamos a criar novos atributos derivados dos atributos anteriores antes de montar um modelo de classificação. Atualmente temos os seguintes atributos: 

1. SESSION - id da sessão
2. DAY - dia do acesso
3. MONTH - mês do acesso
4. TIME - hora do acesso, com minutos representados por quartis: {q1, q2, q3, q4}, exemplo a hora 14:48 é representada como 14.q4 
5. ITEM - id do item
6. CATEGORY - id da categoria
7. WEEKDAY - dia da semana do acesso
8. CLICKED - quantidade de vezes que o item foi clicado (somando todos os usuários)
9. BOUGHT - quantidade de vezes que o item foi comprado (somando todos os usuários)
10. SOLDABILITY - razão de CLICKED por BOUGHT, multiplicado por 100
11. SAME_CAT - quantidade de produtos da categoria do click que também foi clicado pela sessão
12. SOLD_MEAN - média de vendabilidade dos item clicados pela sessão
13. SOLD_MEAN_DIFF - diferença, SOLDABILITY (do item) menos SOLD_MEAN (da sessão) 
14. SOLD_MEDIAN - mediana das vendabilidades dos itens clicados pela sessão
15. SESSION_SIZE - número de clicks que a sessão deu
16. IS_BUY - 0 para para não compra e 1 para compra
17. CATEG_MOST - categoria de maior ocorrência do item
18. SESSION_DURATION - duração, em segundos, da sessão
19. RELATIVE_TIME = diferença de tempo entre o click e o primeiro click da sessão
20. RELATIVE_TIME_PROP = razão relative_time / session_duration

Como o dataset é bastante grande, para esse experimento vamos utilizar apenas 0.1% do dataset. Essa amostra foi retirada de forma aleatória. 

```{r, message=FALSE}
require(ggplot2)
require(dplyr)

recSys<- read.csv("~/Projetos/DataAnalysis/Assignment4/RecSys.csv")

colnames(recSys) <- c("SESSION", "DAY", "MONTH", "TIME", "ITEM", "CATEGORY", "WEEKDAY", "CLICKED", "BOUGHT", "SOLDABILITY", "SAME_CAT", "SOLD_MEAN", "SOLD_MEAN_DIFF", "SOLD_MEDIAN", "SESSION_SIZE", "CATEG_MOST", "IS_BUY","SESSION_DURATION", "RELATIVE_TIME", "RELATIVE_TIME_PROP")

recSys$SESSION <- as.factor(recSys$SESSION)
recSys$MONTH <- as.factor(recSys$MONTH)
recSys$ITEM <- as.factor(recSys$ITEM)
recSys$IS_BUY <- as.factor(recSys$IS_BUY)

summary(recSys)
```

Olhando apenas para os dados é possível tirar algumas conclusões:

```{r, fig.align='center'}
isBuy <- as.data.frame(summary(recSys$IS_BUY))

isBuy["Compras"] <- c("Não_Compras", "Compras") 
colnames(isBuy) <- c("Quantidade", "Compras")

ggplot(isBuy, aes(x=Compras, y=Quantidade)) + 
  geom_bar(stat="identity") + 
  labs(y='Quantidade de clicks com compra') +
  theme(panel.background=element_blank())
```

Existem muito mais clicks com não compra do que com compras. Mostrando que os dados estão desbalanceados. 5.5% são os clicks com compras e o restante para clicks com não compras. Além disso, podemos obervar uma diferença no volumes de clicks ao longo dos dias da semana:


```{r, fig.align='center'}
weekday <- as.data.frame(summary(recSys$WEEKDAY))

weekday["Dia_da_semana"] <- c("Sexta", "Segunda", "Sábado", "Domingo", "Quinta", "Terça", "Quarta") 
colnames(weekday) <- c("Quantidade", "Dia_da_semana")

ggplot(weekday, aes(x=Dia_da_semana, y=Quantidade)) + 
  geom_bar(stat="identity") + 
  labs(y='Quantidade de clicks') +
  theme(panel.background=element_blank())
```

Nas segundas e nos domingos é possível identificar um maior número de clicks em relação aos outros dias.

A grande maioria das sessões possui menos de 10 clicks. Como podemos observar no histograma abaixo:

```{r, fig.align='center'}
ggplot(recSys, aes(SESSION_SIZE)) + geom_histogram() +  theme_bw()
```


Para melhor avaliar o modelo que será criado, precisamos antes realizar uma divisão nos dados da amostra. Reservando 1/3 da amostra para teste e 2/3 para treino. 

```{r}
indexes = sample(1:nrow(recSys), size=0.3*nrow(recSys))

teste = recSys[indexes,]
treino = recSys[-indexes,]

recSys <- NULL
```

Para o nosso primeiro modelo, vamos inicialmente observar o comportamento do classificador utilizando apenas o dia da semana. 

```{r}
bm <- glm(IS_BUY ~ WEEKDAY, 
          data = treino, 
          family = "binomial")

summary(bm)
exp(bm$coefficients)
```

É possível identificar que em relação a Sexta-Feira, o Sábado e o Domingo são os dias que mais tem chance de ocorrer uma compra. O sábado tem 1.418 mais chances de ocorrer uma compra do que em uma sexta. Já o domingo tem 1.321 mais chances. 

Para testar o nosso classificador vamos utilizar os dados de teste. 

```{r}
predictions <- predict(bm, type = "response", newdata = teste) > 0.07
verdadeiras_compras <- teste$IS_BUY == 1

table(predictions, verdadeiras_compras)
```

Existem dois tipos de erros que podemos observar na tabela acima. O primeiro erro é o falso positivo, que ocorre quando o modelo prediz que uma saída é verdadeira quando na verdade ela é possitiva. Para o nosso caso é o mesmo que dizer que o modelo achou que um click resultava em compra quando na verdade ele resultava em não compra. 

O segundo erro é o falso negativo, que ocorre quando o modelo prediz que uma saída é falsa quando na verdade ela é possitiva. Para o nosso caso é o mesmo que dizer que o modelo achou que um click não era compra quando na verade ele resultava em compra. 

O nosso objetivo é diminuir ao máximo o segundo tipo de erro. Esse modelo testado errou 84% do clicks de compra. Acertando apenas 26% do clicks de compras. Sendo esse um valor muito baixo. 

Em busca de melhorar esse valor, realizamos um novo teste. Dessa vez modificando o limiar para 0.05

```{r}
predictions <- predict(bm, type = "response", newdata = teste) > 0.05
verdadeiras_compras <- teste$IS_BUY == 1

table(predictions, verdadeiras_compras)
```


Nesse modelo temos um erro de 34% dos clicks de compra. O modelo deveria ter classificado como compra e classificou como não compra. 

Em busca de melhorar esse número criamos outro modelo. Dessa vez considerando o máximo de atributos possivel. Devido ao tamanho do dataset decidimos focar em alguns atributos para esse relatório. Os atributos escolhidas foram: SOLDABILITY, WEEKDAY, MONTH, RELATIVE_TIME_PROP, RELATIVE_TIME, SESSION_DURATION, SESSION_SIZE, DAY, BOUGHT. 

```{r}
bm2 <- glm(IS_BUY ~ SOLDABILITY + WEEKDAY + MONTH + RELATIVE_TIME_PROP + RELATIVE_TIME + SESSION_DURATION + SESSION_SIZE + DAY + BOUGHT, 
          data = teste,
          family = "binomial")

summary(bm2)
```


Como os atributos RELATIVE_TIME_PROP, RELATIVE_TIME e DAY se mostraram pouco relevantes, decidimos por tirar esses atributos. 

```{r}
bm2 <- glm(IS_BUY ~ SOLDABILITY + WEEKDAY + MONTH + SESSION_DURATION + SESSION_SIZE + BOUGHT, 
          data = teste,
          family = "binomial")
summary(bm2)

predictions <- predict(bm2, type = "response", newdata = teste) > 0.05
verdadeiras_compras <- teste$IS_BUY == 1

table(predictions, verdadeiras_compras)
```

Para esse novo modelo testado temos um erro de 31% do clicks de compra. Acertando 69% do clicks de compras. Sendo esse um valor muito mais alto em comparação ao nosso primeiro modelo.

Nos próximos passos temos que derivar mais atributos para assim diminuir o valor dos falsos positivos. 